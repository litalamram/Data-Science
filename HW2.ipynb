{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Download the \"Boston1.csv\" database, and explore the data. Explanation about the dataset can be found here: http://www.clemson.edu/economics/faculty/wilson/R-tutorial/analyzing_data.html\n",
    "\n",
    "Find the columns with missing values and filter them out of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "misData\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "df = pd.read_csv(\"Boston1.csv\")\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "res = pd.isnull(df).sum()\n",
    "for key,value in res.iteritems():\n",
    "    if (value > 0):\n",
    "        print(key)\n",
    "# Filter that columns out of the data.\n",
    "df = df.dropna(axis = 1, how ='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Divide the filtered data randomly into a train set (70% of the data) and test set (30% of the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.sample(frac=0.7)\n",
    "test = df.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't done this previously, install the scikit-learn package for python.\n",
    "\n",
    "a) On the train set, run a linear regression model as follows:\n",
    "Divide the training set into explanatory variables (the X matrix with which we'll try to make a prediction) and a target variable (y, the value which we'll try to predict). Use the 'medv' attribute as the target variable y and the rest of the features as the X matrix. Run a linear regression model on those sets, and print the regression coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression coefficients by attribute:\n",
      "crim : -0.08198171559399449\n",
      "zn : 0.03617654484314045\n",
      "indus : -0.013114399033058973\n",
      "chas : 2.452851447427105\n",
      "nox : -18.717773959723512\n",
      "rm : 4.45013348860549\n",
      "age : -0.008707851666307099\n",
      "dis : -1.648747007843591\n",
      "rad : 0.21601646087013027\n",
      "tax : -0.00956999173345296\n",
      "ptratio : -1.0153924636202987\n",
      "black : 0.009839806088108282\n",
      "lstat : -0.5094595889536119\n",
      "randCol : 0.976633863163581\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "train_x = train.drop(['medv'],axis=1)\n",
    "train_y = train['medv']\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "i=0;\n",
    "print(\"Regression coefficients by attribute:\")\n",
    "for col_lab in train_x.axes[1]:\n",
    "    print(col_lab,\":\",model.coef_[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Use the linear regression model to predict the values of the test set's 'medv' column, based on the test set's other attributes. Print the Mean Squared Error of the model on the train set and on the test set.\n",
    "Usually, the MSE on the train set would be lower than the MSE on the test set, since the model parameters are optimized with respect to the train set. Must this always be the case? Can you think of a few examples for when this might not be the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set MSE: 20.880763213595742\n",
      "Test set MSE: 25.900584529128515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "test_x = test.drop(['medv'],axis=1)\n",
    "test_y = test['medv']\n",
    "\n",
    "predicted_y_train = model.predict(train_x)\n",
    "predicted_y_test = model.predict(test_x)\n",
    "print(\"Train set MSE:\",mse(predicted_y_train, train_y))\n",
    "print(\"Test set MSE:\",mse(predicted_y_test, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example in which the MSE on the test set may be lower than the MSE on the train set is when we have different groups and each of them has perfect linear correlation, but each has different coefficient. Let's say we have 3 different groups as stated, with matching coefficients - n, m, l - and n < m < l. We can pick our test set to include samples mostly from the group with coefficient n the predicted attribute will be closer to the linear model than the predicted attribute of samples from the group with coefficient m. So that will create a test set with a lower MSE than the one on the train set, which will be more scattered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Add some noise (with mean=0, std=1) to the test set's y, and predict it again. What happened to the MSE? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set MSE: 26.10444866946172\n"
     ]
    }
   ],
   "source": [
    "noise = np.random.normal(0, 1, len(test_y.index))\n",
    "noised_test_y = test_y + noise\n",
    "print(\"Test set MSE:\",mse(predicted_y_test, noised_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE slightly changed but is still very close to the original MSE, because the noise distribution is normal, and it is added to the real y values that are also normally distributed, and so the result is a normal distribution with slightly higher sd and the same expectance.Some y values got a little closer to the model and others moved farther but all in all they maintained their over all distance from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Create a Recursive feature elimination model, with a linear regression estimator, that selects half of the original number of features. Hint: Check the feature_selection module in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "mdl = LinearRegression()\n",
    "\n",
    "rfe = RFE(mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Use the feature elimination model on the full database (after filtering columns with missing values, before partitioning into train/test). Print the features that were selected. Remember that we separate the 'medv' attribute to be our y, while the rest of the attributes in the dataset serve as features to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are:\n",
      "['chas' 'nox' 'rm' 'dis' 'ptratio' 'lstat' 'randCol']\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['medv'],axis=1)\n",
    "y = df['medv']\n",
    "selected_model = rfe.fit(X,y)\n",
    "print(\"The selected features are:\")\n",
    "print(X.columns[selected_model.support_].get_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) We'd like to find out the optimal number of features. Create feature elimination models (with linear regression estimators) for every number of features between 1 and n (where n = all the original features, 'medv' excluded). For each number of features, run a linear regression as in Question 2, only on the selected features, in order to predict 'medv'. Print the Mean Sqaured Error for each number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 fetures:\n",
      "train: 76.5877949125\n",
      "test: 51.4411998183\n",
      " 2 fetures:\n",
      "train: 41.4403565693\n",
      "test: 34.4612429806\n",
      " 3 fetures:\n",
      "train: 39.6357193597\n",
      "test: 33.0075951287\n",
      " 4 fetures:\n",
      "train: 34.3266560362\n",
      "test: 28.364876106\n",
      " 5 fetures:\n",
      "train: 32.6223876102\n",
      "test: 27.2033576978\n",
      " 6 fetures:\n",
      "train: 24.5881631221\n",
      "test: 22.9027593296\n",
      " 7 fetures:\n",
      "train: 24.5672716765\n",
      "test: 23.0962812508\n",
      " 8 fetures:\n",
      "train: 24.2949300049\n",
      "test: 23.4801528731\n",
      " 9 fetures:\n",
      "train: 23.6589585851\n",
      "test: 23.2363568002\n",
      " 10 fetures:\n",
      "train: 23.6067420312\n",
      "test: 23.0740303016\n",
      " 11 fetures:\n",
      "train: 23.4166879586\n",
      "test: 24.2964944199\n",
      " 12 fetures:\n",
      "train: 23.2658178969\n",
      "test: 23.7001551875\n",
      " 13 fetures:\n",
      "train: 22.7784912694\n",
      "test: 23.1457693268\n",
      " 14 fetures:\n",
      "train: 22.1870327015\n",
      "test: 22.7770007576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "res_mse = (df.shape[1]-1) * [(0,0)] \n",
    "train_x = train.drop(['medv'],axis=1)\n",
    "train_y = train['medv']\n",
    "test_x = test.drop(['medv'],axis=1)\n",
    "test_y = test['medv']\n",
    "\n",
    "for i in range(1, df.shape[1]):\n",
    "    rfe3 = RFE(mdl, n_features_to_select= i)\n",
    "    exe = rfe3.fit(train_x,train_y)\n",
    "    x_train_c = train[train_x.columns[exe.support_]]\n",
    "    x_test_c = test[train_x.columns[exe.support_]]\n",
    "    mdl.fit(x_train_c, train_y)\n",
    "    res_mse[i-1] = (mse(mdl.predict(x_train_c), train_y), mse(mdl.predict( x_test_c), test_y)) \n",
    "    print(\" {} fetures:\".format(i))\n",
    "    print(\"train: {}\".format(res_mse[i-1][0]))\n",
    "    print(\"test: {}\".format(res_mse[i-1][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Conclude the optimal number of features for this task. Think about the cost of adding for data vs the benefit of a more accurate prediction. Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# x is the nubmer of fetures and y is the value of the MSE.\n",
    "li = list(range(1,15))\n",
    "mse_train = [val[0] for val in res_mse]\n",
    "mse_test = [val[1] for val in res_mse]\n",
    "plt.plot(li,mse_train)\n",
    "plt.plot(li,mse_test)\n",
    "plt.title(\"MSE as a function of features:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal number of features for this task is 6.\n",
    "The MSE of the train set and test set are close to each other when using 6 fetures.\n",
    "Using more features doesn't change much the MSE of the train and test sets.\n",
    "Therefore, consdering the question of cost of adding for data vs the benefit of a more accurate prediction, 6 features is the optimal number of fetures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross-validation of the linear regression on the train set with K=5. Print the CV scores for each repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70200515 0.71562545 0.78560346 0.71049576 0.73803187]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(cross_val_score(mdl, train_x, train_y, cv=5))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
